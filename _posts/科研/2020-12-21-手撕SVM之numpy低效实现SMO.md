---
layout: post
title: æ‰‹æ’•SVMä»£ç ä¹‹numpyä½æ•ˆå®ç°SMOç®—æ³•
category: ç§‘ç ”
tags: æœºå™¨å­¦ä¹ 
keywords: æœºå™¨å­¦ä¹ ,SVM
description: é¢è¯•é‡åˆ°è¿‡çš„é—®é¢˜
---

(æœ¬æ–‡ä½¿ç”¨https://www.codecogs.com/è¿›è¡Œlatexæ¸²æŸ“ï¼Œè‹¥latexå…¬å¼æœ‰é—®é¢˜ï¼Œè¯·å¼€å¯å…¨å±€æ¢¯å­)

ä¸€ç›´ä»¥æ¥SVMéƒ½åœç•™åœ¨ä¸€çœ‹å°±å¤§æ¦‚çŸ¥é“ï¼Œä¸€ä¸Šæ‰‹æ¨å¯¼å°±å‚»çœ¼çš„é˜¶æ®µã€‚å®é™…ä¸Šè¿˜æ˜¯æ²¡æœ‰çœŸæ­£åœ°ç†è§£äº†SVMçš„ç²¾é«“ï¼Œå¯¹äº **å…³é”®å®šç†** è¿™é‡Œæ€»æ˜¯å›«å›µåæ£ã€‚çœ‹ä¸€çœ‹ç½‘ä¸Šå¤§éƒ¨åˆ†çš„æ•™ç¨‹ï¼Œä¹Ÿéƒ½æ˜¯ä»¥æ¨å¯¼ä¸ºä¸»ï¼Œæ‰€ä»¥æƒ³æ‰‹å†™å®ç°ä¸€ä¸‹ï¼ŒåŠ æ·±ç†è§£ã€‚

> talk is cheap, show me the code.

å‡è®¾æˆ‘ä»¬å·²ç»è‰°éš¾åœ°æ¨å¯¼åˆ°äº†æœ€åï¼Œå¾—åˆ°äº†SVMçš„å¯¹å¶é—®é¢˜ä¸Šï¼š

<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;argmax\sum_{i=1}^n{\alpha_{i}}-\frac{1}{2}{\sum_{i=1}^{n}}{\sum_{j=1}^{n}}y_{i}y_{j}\alpha_{i}\alpha_{j}\left&space;\langle&space;x_{i},x_{j}&space;\right&space;\rangle\\&space;s.t.&space;\alpha_{i}\geq0,&space;\sum_{i=1}^{N}\alpha_{i}y_{i}=0" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;argmax\sum_{i=1}^n{\alpha_{i}}-\frac{1}{2}{\sum_{i=1}^{n}}{\sum_{j=1}^{n}}y_{i}y_{j}\alpha_{i}\alpha_{j}\left&space;\langle&space;x_{i},x_{j}&space;\right&space;\rangle\\&space;s.t.&space;\alpha_{i}\geq0,&space;\sum_{i=1}^{N}\alpha_{i}y_{i}=0" title="\large argmax\sum_{i=1}^n{\alpha_{i}}-\frac{1}{2}{\sum_{i=1}^{n}}{\sum_{j=1}^{n}}y_{i}y_{j}\alpha_{i}\alpha_{j}\left \langle x_{i},x_{j} \right \rangle\\ s.t. \alpha_{i}\geq0, \sum_{i=1}^{N}\alpha_{i}y_{i}=0" /></a></center></p>

è¿™æ—¶å€™ï¼Œæˆ‘ä»¬éœ€è¦æ±‚è§£ä¸€ç³»åˆ—çš„<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1},\alpha_{2},\alpha_{3}..." target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1},\alpha_{2},\alpha_{3}..." title="\large \alpha_{1},\alpha_{2},\alpha_{3}..." /></a>å€¼äº†ï¼Œåªè¦å¾—åˆ°äº† <a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}" title="\large \alpha_{1}" /></a>çš„å€¼ï¼Œé‚£ä¹ˆW,b å°±å¥½æ±‚äº†ã€‚[ã€Šè¥¿ç“œä¹¦ã€‹](https://book.douban.com/subject/26708119/)ä¸Šä¹Ÿå°±åˆ°äº†è¿™é‡Œï¼Œå‘Šè¯‰æˆ‘ä»¬è¿™æ˜¯ä¸€ä¸ªäºŒæ¬¡è§„åˆ’é—®é¢˜ï¼ˆè¿™æˆ‘ä¹Ÿä¸ä¼šå•ŠğŸ˜­ï¼‰ã€‚é¡ºç†æˆç« åœ°å¼•å…¥äº† SMO ç®—æ³•æ¥æ±‚è§£<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}" title="\large \alpha_{1}" /></a>ï¼Œå¾—åˆ°äº†<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}" title="\large \alpha_{1}" /></a>åï¼Œå¯¹W,bè¿›è¡Œæ›´æ–°è¿­ä»£ï¼š

<div>![](https://github.com/anxingle/anxingle.github.io/blob/master/public/img/ML/svm_latex.png?raw=true)


å³å¯æ±‚å‡ºè¶…åˆ†ç±»é¢ï¼Œä¹Ÿå°±æ˜¯åˆ†ç±»å‡½æ•°:

<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;f(x)=W^Tx&plus;b&space;=&space;\sum_{i=1}^m\alpha_{i}y_{i}x_{i}^T&plus;b" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;f(x)=W^Tx&plus;b&space;=&space;\sum_{i=1}^m\alpha_{i}y_{i}x_{i}^T&plus;b" title="\large f(x)=W^Tx+b = \sum_{i=1}^m\alpha_{i}y_{i}x_{i}^T+b" /></a></center></p>
è¿™æ˜¯åŸºæœ¬çš„SVMæ¨å¯¼ï¼Œå¦‚æœè¿™ä¸€æ­¥è¿˜ä¸çŸ¥é“æ€ä¹ˆæ¥çš„ï¼Œé‚£å°±éœ€è¦æ‹¿[ã€Šè¥¿ç“œä¹¦ã€‹](https://book.douban.com/subject/26708119/)å¥½å¥½æ¨å¯¼ä¸€ä¸‹äº†ã€‚
<center><embed src="https://raw.githubusercontent.com/anxingle/Exam/dac71b6b54ac42b41cc76cb8996c030d18f58c26/pic/SMO.pdf" width="900" height="400"></center>

æˆ‘ä»¬å›è¿‡å¤´æ¥ç»§ç»­çœ‹SMOç®—æ³•å¦‚ä½•æ¥æ±‚è§£çš„<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1,2,3...}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1,2,3...}" title="\large \alpha_{1,2,3...}" /></a> ï¼Œå®é™…ä¸Šè¿™é‡Œæˆ‘ä¹Ÿä¸èƒ½æ˜ç™½SMOçš„ç²¾é«“ï¼Œåªèƒ½æŒ‰ç€ [wikipedia SMOåºåˆ—æœ€å°ä¼˜åŒ–ç®—æ³•](https://zh.wikipedia.org/wiki/åºåˆ—æœ€å°ä¼˜åŒ–ç®—æ³•ä¸­)  ä»‹ç»çš„çš„æµç¨‹æ¥è¿›è¡Œè®¡ç®—äº†ğŸ˜ã€‚

![](https://github.com/anxingle/anxingle.github.io/blob/master/public/img/ML/smo.jpeg?raw=true)

å…¶ä¸­ï¼Œ$L$å’Œ$H$åˆ†åˆ«æ˜¯$\alpha_{2}^{new}$ çš„ä¸‹ç•Œå’Œä¸Šç•Œã€‚ç‰¹åˆ«åœ°ï¼Œæœ‰ï¼š
![](https://github.com/anxingle/anxingle.github.io/blob/master/public/img/ML/smo2.jpeg?raw=true)

æ¨å¯¼è¿‡ç¨‹å®åœ¨ç¹çï¼Œæˆ‘ä»¬è¿™é‡Œç›´æ¥æ‹¿ä½œè€…çš„è§£æè§£ï¼š

> è®°  <a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\eta=K_{1}^1&space;&plus;&space;K_{2}^2&space;-&space;2K_{1,2}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\eta=K_{1}^1&space;&plus;&space;K_{2}^2&space;-&space;2K_{1,2}" title="\large \eta=K_{1}^1 + K_{2}^2 - 2K_{1,2}" /></a>, è¿™é‡Œ<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;K(x1,&space;x2)" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;K(x1,&space;x2)" title="\large K(x1, x2)" /></a>ä¸ºæ ¸å‡½æ•°ï¼Œç”¨äºå°†ä½ç»´ç©ºé—´çš„æ•°æ®æ˜ å°„åˆ°é«˜ç»´ç©ºé—´ï¼Œæˆ‘ä»¬ä»¥åå†è°ˆï¼›

> è®°<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;E_{i}=f(x_{i})-y_{i}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;E_{i}=f(x_{i})-y_{i}" title="\large E_{i}=f(x_{i})-y_{i}" /></a>,ä¹Ÿå°±æ˜¯æ›´æ–°åçš„SVMé¢„æµ‹å€¼ä¸çœŸå®å€¼çš„è¯¯å·®ã€‚

å¾—åˆ°ï¼š
<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{2}^{new}&space;=&space;\alpha_{2}^{old}&plus;{y_{2}}\frac{&space;(E_{1}&space;-&space;E_{2})&space;}{\eta}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{2}^{new}&space;=&space;\alpha_{2}^{old}&plus;{y_{2}}\frac{&space;(E_{1}&space;-&space;E_{2})&space;}{\eta}" title="\large \alpha_{2}^{new} = \alpha_{2}^{old}+{y_{2}}\frac{ (E_{1} - E_{2}) }{\eta}" /></a></center></p>

æ­¤æ—¶æœªè€ƒè™‘çº¦æŸæ¡ä»¶ä¸‹çš„è§£ï¼Œå¦‚æœè€ƒè™‘çº¦æŸï¼š
<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}y_{1}&plus;\alpha_{2}y_{2}=-\sum_{i=1}^n{\alpha_{i}{y_{i}}}=\zeta;&space;0\leq\alpha_{i}\leq{C}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}y_{1}&plus;\alpha_{2}y_{2}=-\sum_{i=1}^n{\alpha_{i}{y_{i}}}=\zeta;&space;0\leq\alpha_{i}\leq{C}" title="\large \alpha_{1}y_{1}+\alpha_{2}y_{2}=-\sum_{i=1}^n{\alpha_{i}{y_{i}}}=\zeta; 0\leq\alpha_{i}\leq{C}" /></a></center></p>

å³å¯å¾—ä¸Šä¸‹ç•Œï¼š
<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\text{if:}&space;y1\neq&space;y2\\\\&space;\left\{\begin{aligned}&space;L=max(0,&space;\alpha_{2}^{old}-\alpha_{1}^{old}),\\&space;H=min(C,&space;C&plus;\alpha_{2}^{old}-\alpha_{1}^{old})&space;\end{aligned}&space;\right." target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\text{if:}&space;y1\neq&space;y2\\\\&space;\left\{\begin{aligned}&space;L=max(0,&space;\alpha_{2}^{old}-\alpha_{1}^{old}),\\&space;H=min(C,&space;C&plus;\alpha_{2}^{old}-\alpha_{1}^{old})&space;\end{aligned}&space;\right." title="\large \text{if:} y1\neq y2\\\\ \left\{\begin{aligned} L=max(0, \alpha_{2}^{old}-\alpha_{1}^{old}),\\ H=min(C, C+\alpha_{2}^{old}-\alpha_{1}^{old}) \end{aligned} \right." /></a></center></p>

ä»¥åŠï¼š
<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\text{if:}&space;{y1}=&space;{y2}\\\\&space;\left\{\begin{aligned}&space;L=max(0,&space;\alpha_{2}^{old}&plus;\alpha_{1}^{old}-C),\\&space;H=min(C,&space;C&plus;\alpha_{2}^{old}&plus;\alpha_{1}^{old})&space;\end{aligned}&space;\right." target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\text{if:}&space;{y1}=&space;{y2}\\\\&space;\left\{\begin{aligned}&space;L=max(0,&space;\alpha_{2}^{old}&plus;\alpha_{1}^{old}-C),\\&space;H=min(C,&space;C&plus;\alpha_{2}^{old}&plus;\alpha_{1}^{old})&space;\end{aligned}&space;\right." title="\large \text{if:} {y1}= {y2}\\\\ \left\{\begin{aligned} L=max(0, \alpha_{2}^{old}+\alpha_{1}^{old}-C),\\ H=min(C, C+\alpha_{2}^{old}+\alpha_{1}^{old}) \end{aligned} \right." /></a></center></p>

åˆ™æœ€ç»ˆçš„<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{2}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{2}" title="\large \alpha_{2}" /></a>æ›´æ–°å…¬å¼ä¸º:
<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{2}^{new}=&space;\left\{\begin{array}{l}&space;H,&space;\qquad\qquad\alpha_{2}^{new,&space;unclipped}\geq{H}\\&space;\alpha_{2}^{new,&space;unclipped},&space;L\leq\alpha_{2}^{new,&space;unclipped}\leq{H}\\&space;L,&space;\qquad\qquad\alpha_{2}^{new,&space;unclipped}\leq{L}\\&space;\end{array}&space;\right." target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{2}^{new}=&space;\left\{\begin{array}{l}&space;H,&space;\qquad\qquad\alpha_{2}^{new,&space;unclipped}\geq{H}\\&space;\alpha_{2}^{new,&space;unclipped},&space;L\leq\alpha_{2}^{new,&space;unclipped}\leq{H}\\&space;L,&space;\qquad\qquad\alpha_{2}^{new,&space;unclipped}\leq{L}\\&space;\end{array}&space;\right." title="\large \alpha_{2}^{new}= \left\{\begin{array}{l} H, \qquad\qquad\alpha_{2}^{new, unclipped}\geq{H}\\ \alpha_{2}^{new, unclipped}, L\leq\alpha_{2}^{new, unclipped}\leq{H}\\ L, \qquad\qquad\alpha_{2}^{new, unclipped}\leq{L}\\ \end{array} \right." /></a></center></p>

å¾—åˆ°  <a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{2}^{new}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{2}^{new}" title="\large \alpha_{2}^{new}" /></a> åï¼Œ<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}^{new}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}^{new}" title="\large \alpha_{1}^{new}" /></a>ä¹Ÿå¯ä»¥åŒæ ·æ±‚å‡ºæ¥ï¼š

<p><center><a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{1}^{new}=\alpha_{1}^{old}&space;&plus;&space;y_{1}y_{2}(\alpha_{2}^{old}-\alpha_{2}^{new})" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{1}^{new}=\alpha_{1}^{old}&space;&plus;&space;y_{1}y_{2}(\alpha_{2}^{old}-\alpha_{2}^{new})" title="\large \alpha_{1}^{new}=\alpha_{1}^{old} + y_{1}y_{2}(\alpha_{2}^{old}-\alpha_{2}^{new})" /></a></center></p>ç„¶åå¾ªç¯å¯¹æ‰€æœ‰çš„<a href="https://www.codecogs.com/eqnedit.php?latex=\large&space;\alpha_{i}" target="_blank"><img src="https://latex.codecogs.com/png.latex?\large&space;\alpha_{i}" title="\large \alpha_{i}" /></a>è¿›è¡Œé€‰å–ï¼Œä¾¿å¯ä»¥è¿›è¡Œä¼˜åŒ–æ›´æ–°äº†ã€‚

æ ¹æ®Plattçš„åŸæ–‡æä¾›çš„ä¼ªä»£ç ï¼Œæˆ‘ä»¬æœ‰å¦‚ä¸‹å®ç°ï¼š

```
import numpy as np
import matplotlib.pyplot as plt
import time

from sklearn.datasets import make_blobs,make_circles,make_moons
from sklearn.preprocessing import StandardScaler

class SMOStruct:
	""" æŒ‰ç…§John Plattçš„è®ºæ–‡æ„é€ SMOçš„æ•°æ®ç»“æ„"""
	def __init__(self, X, y, C, kernel, alphas, b, errors, tol, eps, user_linear_optim, loop_threshold=2000):
		self.X = X              # è®­ç»ƒæ ·æœ¬
		self.y = y              # ç±»åˆ« label
		self.C = C              # æ­£åˆ™åŒ–å¸¸é‡ï¼Œç”¨äºè°ƒæ•´ï¼ˆè¿‡ï¼‰æ‹Ÿåˆçš„ç¨‹åº¦
		self.kernel = kernel    # æ ¸å‡½æ•°ï¼Œå®ç°äº†ä¸¤ä¸ªæ ¸å‡½æ•°ï¼Œçº¿æ€§å’Œé«˜æ–¯ï¼ˆRBFï¼‰
		self.alphas = alphas    # æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼Œä¸æ ·æœ¬ä¸€ä¸€ç›¸å¯¹
		self.b = b              # æ ‡é‡ï¼Œåç§»é‡
		self.errors = errors    # ç”¨äºå­˜å‚¨alphaå€¼å®é™…ä¸é¢„æµ‹å€¼å¾—å·®å€¼ï¼Œä¸æ ·æœ¬æ•°é‡ä¸€ä¸€ç›¸å¯¹
		self.tol = tol          # error tolerance
		self.eps = eps          # alpha tolerance

		self.m, self.n = np.shape(self.X)  # è®­ç»ƒæ ·æœ¬çš„ä¸ªæ•°m å’Œ æ¯ä¸ªæ ·æœ¬çš„featuresæ•°é‡n

		self.user_linear_optim = user_linear_optim    # åˆ¤æ–­æ¨¡å‹æ˜¯å¦ä½¿ç”¨çº¿æ€§æ ¸å‡½æ•°
		self.w = np.zeros(self.n)     # åˆå§‹åŒ–æƒé‡wçš„å€¼ï¼Œä¸»è¦ç”¨äºçº¿æ€§æ ¸å‡½æ•°
		#self.b = 0
		self.loop_threshold = loop_threshold
		# å·®å€¼çŸ©é˜µ
		initial_error = SMOStruct.decision_function(self.alphas, self.y, self.kernel, self.X, self.X, self.b) - self.y
		self.errors = initial_error

	# åˆ¤åˆ«å‡½æ•°ä¸€: f(x)=WX-b, ç”¨äºå•ä¸€æ ·æœ¬
	@classmethod
	def decision_function_output(cls, model, i):
		if model.user_linear_optim:
			# Equation (J1)
			# è¿”å›åœ¨å¹³é¢ä¸­çš„ä½ç½®(f(x)=WX-b)
			return float(model.w.T @ model.X[i]) - model.b
		else:
			# Equation (J10)
			return np.sum([model.alphas[j] * model.y[j] * model.kernel(model.X[j], model.X[i]) for j in range(model.m)]) - model.b

	# åˆ¤åˆ«å‡½æ•°äºŒï¼Œç”¨äºå¤šä¸ªæ ·æœ¬
	@staticmethod
	def decision_function(alphas, target, kernel, X_train, x_test, b):
		""" Applies the SVM decision function to the input feature vectors in 'x_test'. """
		result = (alphas * target) @ kernel(X_train, x_test) - b   # *ï¼Œ@ ä¸¤ä¸ªOperatorsçš„åŒºåˆ«?
		return result


	# é€‰æ‹©äº†alpha2, alpha1åå¼€å§‹ç¬¬ä¸€æ­¥ä¼˜åŒ–ï¼Œç„¶åè¿­ä»£
	# ä¸»è¦çš„ä¼˜åŒ–æ­¥éª¤åœ¨è¿™é‡Œå‘ç”Ÿ
	def take_step(self, i1, i2):
		# å¦‚æœä¸¤ä¸ª alphas ç›¸åŒï¼Œè·³è¿‡
		if i1 == i2:
			return 0
		# alpha1, alpha2, y1, y2, E1, E2, s éƒ½æ˜¯è®ºæ–‡ä¸­å‡ºç°çš„å˜é‡ï¼Œå«ä¹‰ä¸è®ºæ–‡ä¸€è‡´
		alpha1 = self.alphas[i1]
		alpha2 = self.alphas[i2]

		y1 = self.y[i1]
		y2 = self.y[i2]

		E1 = get_error(self, i1)
		E2 = get_error(self, i2)
		s = y1 * y2

		# è®¡ç®—alphaçš„è¾¹ç•Œï¼ŒL, H
		if(y1 != y2):
			# y1,y2 å¼‚å·ï¼Œä½¿ç”¨ Equation (J13)
			L = max(0, alpha2 - alpha1)
			H = min(self.C, self.C + alpha2 - alpha1)
		elif (y1 == y2):
			# y1,y2 åŒå·ï¼Œä½¿ç”¨ Equation (J14)
			L = max(0, alpha1 + alpha2 - self.C)
			H = min(self.C, alpha1 + alpha2)
		if L == H:
			return 0

		# åˆ†åˆ«è®¡ç®—æ ·æœ¬1, 2å¯¹åº”çš„æ ¸å‡½æ•°ç»„åˆï¼Œç›®çš„åœ¨äºè®¡ç®—eta  ä¹Ÿå°±æ˜¯æ±‚ä¸€é˜¶å¯¼æ•°åçš„å€¼ï¼Œç›®çš„åœ¨äºè®¡ç®—a2_new
		k11 = self.kernel(self.X[i1], self.X[i1])
		k12 = self.kernel(self.X[i1], self.X[i2])
		k22 = self.kernel(self.X[i2], self.X[i2])
		# è®¡ç®— etaï¼Œequation (J15)
		eta = k11 + k22 - 2*k12

		# å¦‚è®ºæ–‡ä¸­æ‰€è¿°ï¼Œåˆ†ä¸¤ç§æƒ…å†µæ ¹æ® eta ä¸ºæ­£è¿˜æ˜¯ä¸ºè´Ÿæˆ–0æ¥è®¡ç®—è®¡ç®— a2_new

		if(eta>0): 
			# equation (J16) è®¡ç®—alpha2
			a2 = alpha2 + y2 * (E1 - E2)/eta
			# æŠŠa2å¤¹åˆ°é™å®šåŒºé—´ equation ï¼ˆJ17ï¼‰
			if L < a2 < H:
				a2 = a2
			elif (a2 <= L):
				a2 = L
			elif (a2 >= H):
				a2 = H
		# TODO: è¿™é‡Œè¿˜æ²¡æœ‰ææ‡‚
		# if eta is non-positive, move new a2 to bound with greater objective function value
		else:
			# Equation ï¼ˆJ19ï¼‰
			# åœ¨ç‰¹æ®Šæƒ…å†µä¸‹ï¼Œetaå¯èƒ½ä¸ä¸ºæ­£
			f1 = y1*(E1 + self.b) - alpha1*k11 - s*alpha2*k12
			f2 = y2*(E2 + self.b) - s*alpha1*k12 - alpha2*k22

			L1 = alpha1 + s*(alpha2 - L)
			H1 = alpha1 + s*(alpha2 - H)

			Lobj = L1 * f1 + L * f2 + 0.5 * (L1 ** 2) * k11 + 0.5 * (L**2) * k22 + s * L * L1 * k12

			Hobj = H1 * f1 + H * f2 + 0.5 * (H1**2) * k11 + 0.5 * (H**2) * k22 + s * H * H1 * k12

			if Lobj < Hobj - self.eps:
				a2 = L
			elif Lobj > Hobj + self.eps:
				a2 = H
			else:
				a2 = alpha2

		# å½“ new_a2 æ¥è¿‘Cæˆ–0æ—¶å€™ï¼Œå°±è®©å®ƒç­‰äºCæˆ–0
		if a2 <1e-8:
			a2 = 0.0
		elif a2 > (self.C - 1e-8):
			a2 = self.C

		#If examples can't be optimized within epsilon(eps), skip this pair
		if (np.abs(a2 - alpha2) < self.eps * (a2 + alpha2 + self.eps)):
			return 0

		#æ ¹æ®æ–° a2 è®¡ç®—æ–° a1 Equation(J18)
		a1 = alpha1 + s * (alpha2 - a2)

		#æ›´æ–° bias bçš„å€¼ Equation (J20)
		b1 = E1 + y1*(a1 - alpha1) * k11 + y2 * (a2 - alpha2) * k12 + self.b
		#equation (J21)
		b2 = E2 + y1*(a1 - alpha1) * k12 + y2 * (a2 - alpha2) * k22 + self.b

		# Set new threshoold based on if a1 or a2 is bound by L and/or H
		if 0 < a1 and a1 < C:
			b_new = b1
		elif 0 < a2 and a2 < C:
			b_new = b2
		# Average thresholds if both are bound
		else:
			b_new = (b1 + b2) * 0.5

		# æ›´æ–°æ¨¡å‹çš„ b
		self.b = b_new

		# å½“æ‰€è®­ç»ƒæ¨¡å‹ä¸ºçº¿æ€§æ ¸å‡½æ•°æ—¶
		# Equation (J22) è®¡ç®—wçš„å€¼
		if self.user_linear_optim:
			 self.w = self.w + y1 * (a1 - alpha1)*self.X[i1] + y2 * (a2 - alpha2) * self.X[i2]
		# åœ¨ alphas çŸ©é˜µä¸­åˆ†åˆ«æ›´æ–°a1, a2çš„å€¼
		self.alphas[i1] = a1
		self.alphas[i2] = a2

		# ä¼˜åŒ–å®Œäº†ï¼Œæ›´æ–°å·®å€¼çŸ©é˜µçš„å¯¹åº”å€¼;  åŒæ—¶æ›´æ–°å·®å€¼çŸ©é˜µå…¶å®ƒå€¼
		self.errors[i1] = 0
		self.errors[i2] = 0

		# æ›´æ–°å·®å€¼ Equation (12)
		for i in range(self.m):
			if 0 < self.alphas[i] < self.C:
				self.errors[i] += y1*(a1 - alpha1) * self.kernel(self.X[i1], self.X[i]) + \
								y2*(a2 - alpha2) * self.kernel(self.X[i2], self.X[i]) + self.b - b_new

		return 1

	def examine_example(self, i2):
		"""
		å¯å‘å¼å¯»æ‰¾ alpha1
		"""
		y2 = self.y[i2]
		alpha2 = self.alphas[i2]
		E2 = get_error(self, i2)
		r2 = E2 * y2

		#XXX: è¿™ä¸€æ®µçš„é‡ç‚¹åœ¨äºç¡®å®š alpha1, ä¹Ÿå°±æ˜¯ old_a1ï¼Œå¹¶é€åˆ° take_step å»åˆ†æä¼˜åŒ–
		# ä¸‹é¢æ¡ä»¶ä¹‹ä¸€æ»¡è¶³ï¼Œè¿›å…¥ if å¼€å§‹æ‰¾ç¬¬äºŒä¸ª alphaï¼Œé€åˆ° take_step è¿›è¡Œä¼˜åŒ–
		if ((r2 < -self.tol and alpha2 < self.C) or (r2 > self.tol and alpha2 > 0)):
			if len(self.alphas[(self.alphas != 0) & (self.alphas != self.C)]) > 1:
				# é€‰æ‹©EiçŸ©é˜µä¸­å·®å€¼æœ€å¤§çš„å…ˆè¿›è¡Œä¼˜åŒ–
				# è¦æƒ³|E1-E2|æœ€å¤§ï¼Œåªéœ€è¦åœ¨E2ä¸ºæ­£æ—¶ï¼Œé€‰æ‹©æœ€å°çš„Eiä½œä¸ºE1
				# åœ¨E2ä¸ºè´Ÿæ—¶é€‰æ‹©æœ€å¤§çš„Eiä½œä¸ºE1
				if self.errors[i2] > 0:
					i1 = np.argmin(self.errors)
				elif self.errors[i2] <= 0:
					i1 = np.argmax(self.errors)

				step_result = self.take_step(i1, i2)
				if step_result:
					return 1

			# å¾ªç¯æ‰€æœ‰é0 éC alphaså€¼è¿›è¡Œä¼˜åŒ–ï¼Œéšæœºé€‰æ‹©èµ·å§‹ç‚¹
			for i1 in np.roll(np.where((self.alphas != 0) & (self.alphas != self.C))[0],
							  np.random.choice(np.arange(self.m))):
				step_result = self.take_step(i1, i2)
				if step_result:
					return 1

			#a2ç¡®å®šçš„æƒ…å†µä¸‹ï¼Œå¦‚ä½•é€‰æ‹©a1? å¾ªç¯æ‰€æœ‰(m-1) alphas, éšæœºé€‰æ‹©èµ·å§‹ç‚¹
			for i1 in np.roll(np.arange(self.m), np.random.choice(np.arange(self.m))):
				#print("what is the first i1",i1)
				step_result = self.take_step(i1, i2)

				if step_result:
					return 1
		#å…ˆçœ‹æœ€ä¸Šé¢çš„ifè¯­å¥ï¼Œå¦‚æœifæ¡ä»¶ä¸æ»¡è¶³ï¼Œè¯´æ˜KKTæ¡ä»¶å·²æ»¡è¶³ï¼Œæ‰¾å…¶å®ƒæ ·æœ¬è¿›è¡Œä¼˜åŒ–ï¼Œåˆ™æ‰§è¡Œä¸‹é¢è¿™å¥ï¼Œé€€å‡º
		return 0

	def fit(self):
		"""
		ç¡®å®šç¬¬ä¸€ä¸ªalpha: alpha2
		"""
		numChanged = 0 # alpha æ›´æ–°é‡
		examineAll = True # éœ€è¦éå†æ‰€æœ‰æ ·æœ¬

		# è®¡æ•°å™¨ï¼Œè®°å½•ä¼˜åŒ–æ—¶çš„å¾ªç¯æ¬¡æ•°
		loopnum = 0
		loopnum1 = 0
		loopnum2 = 0

		"""
		å½“numChanged = 0(alphaæ²¡æœ‰æ›´æ–°) and examineAll(ä¸å†éœ€è¦éå†æ ·æœ¬)æ—¶ å¾ªç¯é€€å‡º
		å®é™…æ˜¯é¡ºåºåœ°æ‰§è¡Œå®Œæ‰€æœ‰çš„æ ·æœ¬ (ç¬¬ä¸€ä¸ªifä¸­çš„å¾ªç¯)
		elseä¸­çš„å¾ªç¯æ²¡æœ‰å¯ä¼˜åŒ–çš„ alpha, ç›®æ ‡å‡½æ•°æ”¶æ•›äº†; ä¸”åœ¨å®¹å·®ä¹‹å†…, å¹¶ä¸”æ»¡è¶³KKTæ¡ä»¶; åˆ™å¾ªç¯é€€å‡ºï¼Œå¦‚æœæ‰§è¡Œ3000æ¬¡å¾ªç¯ä»æœªæ”¶æ•›, ä¹Ÿé€€å‡º
		"""

		# XXX: ç¡®å®š alpha2ï¼Œä¹Ÿå°±æ˜¯old_a2, æˆ–è€…è¯´alpha2çš„ä¸‹æ ‡ï¼Œold_a2 å’Œ old_a1éƒ½æ˜¯å¯å‘å¼é€‰æ‹©
		while(numChanged > 0) or (examineAll): 
			numChanged = 0
			if loopnum == self.loop_threshold: # å¾ªç¯é‡å¤§äºæœ€å¤§é˜ˆå€¼
				break
			loopnum = loopnum + 1

			if examineAll:
				loopnum1 = loopnum1 + 1 # è®°å½•é¡ºåºä¸€ä¸ªä¸€ä¸ªé€‰æ‹© alpha2 æ—¶çš„å¾ªç¯æ¬¡æ•°
				# ä»0,1,2,3,...,mé¡ºåºé€‰æ‹© a2 çš„ï¼Œé€ç»™ examine_example é€‰æ‹© alpha1ï¼Œæ€»å…± m*(m-1)ç§é€‰æ³•
				for i in range(self.alphas.shape[0]): 
					examine_result = self.examine_example(i) # æ˜¯å¦å‘ç”Ÿæ”¹å˜
					numChanged += examine_result
			else:  # ä¸Šé¢ifé‡Œm(m-1)æ‰§è¡Œå®Œçš„åæ‰§è¡Œ 
				loopnum2 = loopnum2 + 1
				# éå†æ ·æœ¬ä¸­ alphas æœªæ›´æ–°çš„å€¼
				for i in np.where((self.alphas != 0) & (self.alphas != self.C))[0]:
					examine_result = self.examine_example(i)
					numChanged += examine_result

			if examineAll:
				examineAll = False
			elif numChanged == 0:
				examineAll = True
		print(" loopnum012: %s, : %s,  : %s" % (loopnum, loopnum1, loopnum2))


def linear_kernel(x, y, b=1):
	#çº¿æ€§æ ¸å‡½æ•°
	""" returns the linear combination of arrays 'x' and 'y' with
	the optional bias term 'b' (set to 1 by default). """
	result = x @ y.T + b
	return result # Note the @ operator for matrix multiplications


def gaussian_kernel(x, y, sigma=1):
	#é«˜æ–¯æ ¸å‡½æ•°
	"""Returns the gaussian similarity of arrays 'x' and 'y' with
	kernel width paramenter 'sigma' (set to 1 by default)"""

	if np.ndim(x) == 1 and np.ndim(y) == 1:
		result = np.exp(-(np.linalg.norm(x-y,2))**2/(2*sigma**2))
	elif(np.ndim(x)>1 and np.ndim(y) == 1) or (np.ndim(x) == 1 and np.ndim(y)>1):
		result = np.exp(-(np.linalg.norm(x-y, 2, axis=1)**2)/(2*sigma**2))
	elif np.ndim(x) > 1 and np.ndim(y) > 1 :
		result = np.exp(-(np.linalg.norm(x[:, np.newaxis]- y[np.newaxis, :], 2, axis = 2) ** 2)/(2*sigma**2))
	return result






def get_error(model, i1):
	if 0< model.alphas[i1] <model.C:
		return model.errors[i1]
	else:
		return SMOStruct.decision_function_output(model, i1) - model.y[i1]

def plot_decision_boundary(model, ax, resolution=100, colors=('b','k','r'), levels = (-1, 0, 1)):
	"""
	ç»˜å‡ºåˆ†å‰²å¹³é¢åŠæ”¯æŒå¹³é¢ï¼Œ
	ç”¨çš„æ˜¯ç­‰é«˜çº¿çš„æ–¹æ³•ï¼Œæ€€ç–‘ç»˜åˆ¶çš„åˆ†å‰²å¹³é¢å’Œæ”¯æŒå¹³é¢çš„å‡†ç¡®æ€§
	"""
	# Generate coordinate grid of shape [resolution x resolution]
	# and evalute the model over the entire space
	x_range = np.linspace(model.X[:, 0].min(), model.X[:, 0].max(), resolution)
	yrange = np.linspace(model.X[:, 1].min(), model.X[:, 1].max(), resolution)
	grid = [[SMOStruct.decision_function(model.alphas, model.y, model.kernel, model.X,
							   np.array([xr,yr]), model.b) for xr in x_range] for yr in yrange]

	grid = np.array(grid).reshape(len(x_range), len(yrange))

	# Plot decision contours using grid and make a scatter plot of training data
	ax.contour(x_range, yrange, grid, levels=levels, linewidths = (1,1,1),
				linestyles=('--', '-', '--'), colors=colors)
	ax.scatter(model.X[:, 0], model.X[:, 1],
				c=model.y, cmap=plt.cm.viridis, lw=0, alpha =0.25)

	# Plot support vectors (non-zero alphas) as circled points (linewidth >0)
	mask = np.round(model.alphas, decimals = 2) !=0.0
	ax.scatter(model.X[mask, 0], model.X[mask, 1],
				c=model.y[mask], cmap=plt.cm.viridis, lw=1, edgecolors='k')

	return grid, ax


if __name__ == '__main__':
	# ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼Œè®­ç»ƒæ ·æœ¬
	X_train, y = make_blobs(n_samples = 1000, centers =2, n_features=2, random_state = 2)
	# StandardScaler()ä»¥åŠfit_transfromå‡½æ•°çš„ä½œç”¨éœ€è¦è§£é‡Šä¸€ä¸‹
	scaler = StandardScaler()   #æ•°æ®é¢„å¤„ç†ï¼Œä½¿å¾—ç»è¿‡å¤„ç†çš„æ•°æ®ç¬¦åˆæ­£æ€åˆ†å¸ƒï¼Œå³å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®ä¸º1
	X_train_scaled = scaler.fit_transform(X_train, y)
	y[y == 0] = -1

	# å°†è®­ç»ƒæ•°æ®ç»˜åˆ¶å‡ºæ¥
	fig, ax = plt.subplots()
	ax.scatter(X_train_scaled[:, 0], X_train_scaled[:, 1],
					c=y, cmap=plt.cm.viridis, lw=0, alpha =0.25)
	plt.show()
	plt.savefig('./train_data.jpg')


	# SVMè¶…å‚æ•°
	C = 20.0 # è½¯é—´éš”-æƒ©ç½šå› å­
	m = len(X_train_scaled) # æ ·æœ¬æ•°
	initial_alphas = np.zeros(m) # åˆå§‹åŒ– alphas
	initial_b = 0.0 # åˆå§‹åŒ– b
	tol = 0.01 # error å®¹å¿åº¦
	eps = 0.01 # alpha å®¹å¿åº¦

	model = SMOStruct(X_train_scaled, y, C, linear_kernel, initial_alphas, initial_b, np.zeros(m), tol, eps, user_linear_optim=True)

	print("starting to fit...")
	start = time.time()
	# å¼€å§‹è®­ç»ƒ
	model.fit()
	print("fit cost time: ", time.time()-start)
	# ç»˜åˆ¶è®­ç»ƒå®Œï¼Œæ‰¾åˆ°åˆ†å‰²å¹³é¢çš„å›¾
	fig, ax = plt.subplots()
	grid, ax = plot_decision_boundary(model, ax)
	plt.show()
	plt.savefig('./svm.jpg')
```

